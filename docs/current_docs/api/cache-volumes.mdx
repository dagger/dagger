---
slug: /api/cache-volumes
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Cache Volumes

Volume caching involves caching specific parts of the filesystem and reusing them on subsequent function calls if they are unchanged. This is especially useful when dealing with package managers such as `npm`, `maven`, `pip` and similar. Since these dependencies are usually locked to specific versions in the application's manifest, re-downloading them on every session is inefficient and time-consuming. By using a cache volume for these dependencies, Dagger can reuse the cached contents across Dagger Function runs and reduce execution time.

Here's an example, which creates two cache volumes for Node.js dependencies:

<Tabs groupId="language">
<TabItem value="Dagger CLI">

```shell
dagger core container \
  from --address=node:21 \
  with-directory --path=/src --directory=https://github.com/dagger/hello-dagger \
  with-workdir --path=/src \
  with-mounted-cache --path=/src/node_modules --cache=node-21-myapp-myenv \
  with-mounted-cache --path=/root/.npm --cache=node-21 \
  with-exec --args="npm","install"
```

</TabItem>
<TabItem value="Go">

```go file=../cookbook/snippets/cache-dependencies/go/main.go
```

</TabItem>
<TabItem value="Python">

```python file=../cookbook/snippets/cache-dependencies/python/main.py
```

</TabItem>
<TabItem value="TypeScript">

```typescript file=../cookbook/snippets/cache-dependencies/typescript/index.ts
```

</TabItem>
</Tabs>

This example will take some time to complete on the first run, as the cache volumes will not exist at that point. Subsequent runs will be significantly faster (assuming there is no other change), since Dagger will simply use the dependencies from the cache volumes instead of downloading them again.

## Cache volumes in Dagger Cloud

Dagger Cloud automatically detects and creates cache volumes when they are declared in your Dagger pipeline or custom functions.

Your cache volumes will appear in the UI within a few minutes after your Dagger function(s) have completed execution. If you don't see them in the UI, ensure you've referenced the volumes correctly in your code and that you've set up your CI or local development workflows to push the cache volumes to Dagger Cloud.

To see your cache volumes, browse to the **Organization Settings** page of the Dagger Cloud dashboard (accessible by clicking your user profile icon in the Dagger Cloud interface) and navigate to the **Configuration** tab. You should see the newly-created volumes listed and enabled.

![Manage volumes](/img/current_docs/api/manage-volumes.png)

You can create as many volumes as needed and manage them from the **Configuration** tab of your Dagger Cloud organization page.

:::tip
If you've configured cache volumes for the first time in a local development environment, call your Dagger function via the Dagger CLI and then run the command `docker container stop -t 300 "$(docker container list --filter 'name=^dagger-engine-*' -q)"`. This step ensures your new cache volumes populate to Dagger Cloud during the engine shutdown phase. You only need to do this the first time you use Dagger Cloud locally with cache volumes or when you add new cache volumes in your Dagger pipeline.
:::

### Implementation

Both cache mechanisms are namespaced by Dagger Cloud Organization name.
- The cache key for the layers cache is `bucket / organization-name / content-address`.
- The cache key for the volumes cache is `bucket / organization-name / volume-name`, where the volume name is set by the user using the Dagger API.
- Manifests of the layers cache are sent to Dagger Cloud to support merging layers between runs (not supported by Buildkit).

The cache is shared across pipelines and runs, within the same Dagger Cloud organization. This implies that users in the same organization share the same cache.

:::important
No cache data is shared across organizations.
:::

### Security

Both caching mechanisms use an object store (S3 or S3-compatible).

Data is encrypted in transit (the transport layer is HTTPS/TLS) and at rest (read more about data encryption in [CloudFlare R2](https://developers.cloudflare.com/r2/reference/data-security/), [AWS S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-bucket-intro.html) and [Google Cloud Storage](https://cloud.google.com/docs/security/encryption/default-encryption)).

## Cache invalidation

### Layer cache invalidation

It may sometimes be necessary to explicitly force execution of specific pipeline steps, bypassing the Dagger layer cache. The typical approach for this is to invalidate the Dagger layer cache by introducing a volatile time variable at a specific point in the Dagger pipeline.

:::note
Changes in mounted cache volumes or secrets do not invalidate the Dagger layer cache.
:::

Here is a simple example:

<Tabs groupId="language">
<TabItem value="Dagger CLI">

```shell
dagger core container \
  from --address=alpine \
  with-env-variable --name="CACHEBUSTER" --value=`(date +%s)` \
  with-exec --args="date"  \
  stdout
```

</TabItem>
<TabItem value="Go">

```go file=../cookbook/snippets/builds/cache/go/main.go
```

</TabItem>
<TabItem value="Python">

```python file=../cookbook/snippets/builds/cache/python/main.py
```

</TabItem>
<TabItem value="TypeScript">

```typescript file=../cookbook/snippets/builds/cache/typescript/index.ts
```

</TabItem>
</Tabs>


In its current form, this example invalidates the cache by printing a different date and time value on every run. However, if the `CACHEBUSTER` environment variable is removed, the same value (the date and time on the first run) is printed on every run.
