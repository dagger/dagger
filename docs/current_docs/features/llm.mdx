---
slug: /features/llm
description: "Quickly build powerful AI agents"
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# LLM Prompting

Dagger can be used as a runtime and programming environment for AI agents. Dagger provides an `LLM` core type that enables native integration of Large Language Models (LLM) in your workflows.

## Prompt mode

Dagger Shell also lets you interact with the attached LLM using natural language commands. Each input builds upon previous interactions, creating a prompt chain that lets you execute complex workflows without needing to know the exact syntax of the underlying Dagger API.

"Prompt mode" can be accessed at any time in the Dagger Shell by typing `>`. Here's an example:

![Prompt mode](/img/current_docs/features/llm-natural.gif)

## Agent loop

Consider the following Dagger Function:

<Tabs groupId="language">
<TabItem value="Go">
```go file=../agents/snippets/coding-agent/go/main.go
```
</TabItem>
<TabItem value="Python">
```python file=../agents/snippets/coding-agent/python/src/coding_agent/main.py
```
</TabItem>
<TabItem value="TypeScript">
```typescript file=../agents/snippets/coding-agent/typescript/src/index.ts
```
</TabItem>
</Tabs>

This Dagger Function creates a new LLM, gives it a workspace container with an assignment, and prompts it to complete the assignment. The LLM then runs in a loop, calling tools and iterating on its work, until it completes the assignment. This loop all happens inside of the LLM object, so the value of `result` is the workspace container with the completed assignment.

## Supported models

Dagger supports a [wide range of popular language models](../configuration/llm.mdx), including those from OpenAI, Anthropic and Google. Dagger can access these models either through their respective cloud-based APIs or using local providers like Ollama. Dagger uses your system's standard environment variables to route LLM requests.

## Observability

Dagger provides [end-to-end tracing](./visualization.mdx) of prompts, tool calls, and even low-level system operations. All agent state changes are observable in real time.

## Learn more

- [Build an AI agent with our quickstart](../agents/quickstart.mdx)
- [Browse AI agent examples](../examples.mdx#ai-agent-examples)
- [Learn about the agent loop and how to work with LLM prompts and responses](../api/llm.mdx)
- [Configure LLM endpoints](../configuration/llm.mdx)
