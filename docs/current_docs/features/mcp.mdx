---
slug: /features/model-context-protocol
description: "Easily give AI agents Environments"
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MCP

Dagger can be used as a runtime and programming environment for AI agents. Dagger provides an `LLM` core type that enables native integration of Large Language Models (LLM) in your workflows.

MCP support in Dagger can be broken into three categories:

1. MCP within Dagger
2. Exposing MCP outside of Dagger
3. Connecting to external MCP from Dagger

## MCP within Dagger

A key feature of Dagger's LLM integration is out-of-the-box support for MCP using Dagger Functions: an LLM can automatically discover and use any and all available Dagger Functions in your Module.

Here's an example of Dagger's LLM bindings in action:

<Tabs groupId="shell">

<TabItem value="Dagger Shell">
```shell title="First type 'dagger' for interactive mode."
llm | with-container $(container | from alpine) | with-prompt "You have an alpine container. Install tools to develop with Python." | container | terminal
```
</TabItem>

<TabItem value="System shell">
```shell
dagger <<EOF
llm |
  with-container \$(container | from alpine) |
  with-prompt "You have an alpine container. Install tools to develop with Python." |
  container |
  terminal
EOF
```
</TabItem>

</Tabs>

![LLM bindings](/img/current_docs/features/llm-api.gif)

## Exposing MCP outside of Dagger

TODO: Document experimental feature.

## Connecting to External MCP Server from Dagger

Support for connecting to external MCP servers from Dagger is coming soon.

## Learn more

- [Build an AI agent with our quickstart](../agents/quickstart.mdx)
- [Browse AI agent examples](../examples.mdx#ai-agent-examples)
- [Learn about the agent loop and how to work with LLM prompts and responses](../api/llm.mdx)
- [Configure LLM endpoints](../configuration/llm.mdx)
